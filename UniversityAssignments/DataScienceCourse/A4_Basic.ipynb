{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "baby_df = pd.read_csv('amazon_baby.csv')\n",
    "baby_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!\n"
     ]
    }
   ],
   "source": [
    "print(baby_df['review'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive $\\geq4$ ratings to 1 and negative $\\leq2$ to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock\n"
     ]
    }
   ],
   "source": [
    "# b) replace all nan's with empty strings\n",
    "baby_df['review'] = baby_df['review'].fillna('')\n",
    "\n",
    "# a) remove punctuaction\n",
    "trans = str.maketrans('','',string.punctuation)\n",
    "\n",
    "# using separator that doesn't exists in out data\n",
    "sep = chr(0)\n",
    "\n",
    "# much faster than apply method\n",
    "baby_df['review'] = sep.join(baby_df['review'].tolist()).translate(trans).split(sep)\n",
    "\n",
    "\n",
    "\n",
    "print(baby_df['review'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "1  it came early and was not disappointed i love ...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase  I h...       5  \n",
       "4  All of my kids have cried nonstop when I tried...       5  \n",
       "5  When the Binky Fairy came to our house we didn...       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c)\n",
    "baby_df = baby_df[baby_df['rating']!=3]\n",
    "baby_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.682247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.731124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating\n",
       "count  166752.000000\n",
       "mean        0.682247\n",
       "std         0.731124\n",
       "min        -1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d)\n",
    "#baby_df.loc[ baby_df['rating'] < 0, 'rating' ] = -1\n",
    "#baby_df.loc[ baby_df['rating'] > 0, 'rating' ] = 1\n",
    "# assuming negative are < 3\n",
    "\n",
    "baby_df.loc[ baby_df['rating'] < 3, 'rating' ] = -1\n",
    "baby_df.loc[ baby_df['rating'] > 3, 'rating' ] = 1\n",
    "baby_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\_uj_\\21_22_sem1\\DataScience\\env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X_train_example.todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "# a)\n",
    "# X = baby_df['review'].values\n",
    "X = baby_df['review']\n",
    "# y = baby_df['rating'].values\n",
    "y = baby_df['rating']\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,y, test_size = 0.25, random_state = 4)\n",
    "X_test_ = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "# with default(1000) iteration number algorithm fails to converge\n",
    "model = LogisticRegression(max_iter = 2000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative words: worst, dissapointed, theory, useless, worthless, disappointing, poorly, unusable, unacceptable, terrible\n",
      "Most positive words: perfect, awesome, hesitate, pleasantly, skeptical, lifesaver, penny, saves, rich, ply\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "coef = model.coef_[0]\n",
    "tmp = np.argsort(coef)\n",
    "names = vectorizer.get_feature_names_out()\n",
    "\n",
    "worst = tmp[:10]\n",
    "best = tmp[-10:]\n",
    "\n",
    "print('Most negative words:', ', '.join(np.take(names,worst)))\n",
    "print('Most positive words:', ', '.join(np.take(names,best)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[[9.99619411e-01 3.80588670e-04]\n",
      " [9.99602958e-01 3.97041856e-04]\n",
      " [9.93656973e-01 6.34302679e-03]\n",
      " [1.00428253e-01 8.99571747e-01]\n",
      " [5.33195222e-02 9.46680478e-01]\n",
      " [1.36344068e-01 8.63655932e-01]\n",
      " [1.16180959e-04 9.99883819e-01]\n",
      " [1.49475310e-08 9.99999985e-01]\n",
      " [9.46040089e-02 9.05395991e-01]\n",
      " [1.93133068e-02 9.80686693e-01]]\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "print(model.classes_)\n",
    "prob_pred = model.predict_proba(X_test)\n",
    "print(prob_pred[:10])\n",
    "#hint: model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive reviews:\n",
      "180646    After much research I purchased an Urbo2 Its e...\n",
      "144112    Background Ive been using Grovia diapers for f...\n",
      "147949    Amazing Love Love Love it  All 5 STARS all the...\n",
      "176040    I went back to work full time just six weeks a...\n",
      "180953    AMAZING stroller  It took me about 2 minutes t...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Most negative reviews:\n",
      "175191    I had to return this stroller for three reason...\n",
      "87026     First off I did manage to find this product fo...\n",
      "10180     Please see my email to the companyHelloI am wr...\n",
      "120707    The previous reviewers laud the piece of mind ...\n",
      "178360    I have rated and left reviews for many items o...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#c) \n",
    "negative = prob_pred[:,0]\n",
    "positive = prob_pred[:,1]\n",
    "\n",
    "print('Most positive reviews:')\n",
    "print(np.take(X_test_,np.argsort(positive)[-5:]))\n",
    "print('')\n",
    "print('Most negative reviews:')\n",
    "print(np.take(X_test_,np.argsort(negative)[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306754941469967\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "limited_vec = CountVectorizer()\n",
    "# learn words from dictionary\n",
    "limited_vec.fit(significant_words)\n",
    "\n",
    "X = baby_df['review']\n",
    "y = baby_df['rating']\n",
    "\n",
    "# split data\n",
    "X_train_l,X_test_l,y_train_l,y_test_l = train_test_split(X,y, random_state = 15, test_size = 0.2)\n",
    "\n",
    "X_test_l_ = X_test_l\n",
    "# transform\n",
    "X_train_l = limited_vec.transform(X_train_l)\n",
    "X_test_l = limited_vec.transform(X_test_l)\n",
    "\n",
    "model_limited = LogisticRegression(max_iter = 2000)\n",
    "\n",
    "model_limited.fit(X_train_l,y_train_l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting is mush faster with limited dictionary, 98.9s vs 12.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most negative words: disappointed, return, waste, broke, money, work, even, would, product, less\n",
      "Most positive words: car, old, able, well, little, great, easy, love, perfect, loves\n"
     ]
    }
   ],
   "source": [
    "coef = model_limited.coef_[0]\n",
    "\n",
    "tmp = np.argsort(coef)\n",
    "names = limited_vec.get_feature_names_out() \n",
    "\n",
    "worst = tmp[:10]\n",
    "best = tmp[-10:]\n",
    "print('Most negative words:', ', '.join(np.take(names,worst)))\n",
    "print('Most positive words:', ', '.join(np.take(names,best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive reviews:\n",
      "27089     I am 8 months pregnant and after our most rece...\n",
      "68018     i purchased the black BUILT NY diaper bag and ...\n",
      "147975    Let me start by saying that I have gone throug...\n",
      "151056    I did tons of research on strollers I knew I w...\n",
      "103297    I was very excited when I heard Chicco was fin...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Most negative reviews:\n",
      "167296    the message 8220Out of Range 8220 is in the mo...\n",
      "113785    We have the Britax Marathon Convertible Car Se...\n",
      "24325     This never worked right and I tried to return ...\n",
      "121156    I added this product Dr Browns BPA Free Deluxe...\n",
      "22491     My wife has been sucessful using the pump but ...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model_limited.predict_proba(X_test_l)\n",
    "\n",
    "lPositive = np.argsort(y_pred_proba[:,1])\n",
    "lNegative = np.argsort(y_pred_proba[:,0])\n",
    "\n",
    "print('Most positive reviews:')\n",
    "print(np.take(X_test_l_,lPositive[-5:]))\n",
    "print('')\n",
    "print('Most negative reviews:')\n",
    "print(np.take(X_test_l_,lNegative[-5:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        word    impact\n",
      "disappointed -2.305434\n",
      "      return -2.060137\n",
      "       waste -1.978250\n",
      "       broke -1.675744\n",
      "       money -0.889217\n",
      "        work -0.623915\n",
      "        even -0.535602\n",
      "       would -0.333011\n",
      "     product -0.319120\n",
      "        less -0.167600\n",
      "         car  0.066429\n",
      "         old  0.104351\n",
      "        able  0.211537\n",
      "        well  0.502414\n",
      "      little  0.509981\n",
      "       great  0.931909\n",
      "        easy  1.183541\n",
      "        love  1.372507\n",
      "     perfect  1.511950\n",
      "       loves  1.716172\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "tDF = pd.DataFrame({'word':names,'impact':coef})\n",
    "print(tDF.sort_values('impact').to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 'less', 'car' and 'old' are most neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing prediction and accuracy calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306754941469967\n",
      "Wall time: 29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#c)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "#hint: %time, %timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with limited dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8691493508440526\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_l = model_limited.predict(X_test_l)\n",
    "print(accuracy_score(y_test_l,y_pred_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing model without limited dictionary with limited one:  \n",
    "Longer predict time 29ms vs 4ms  \n",
    "Better accuracy: 0.93 vs 0.86  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3beee5f97c3291cc4fa16d19428a099139405ba9907fd0ed556f3ed4835300f2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
